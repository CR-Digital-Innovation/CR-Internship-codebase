{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTrWcds1YF7N"
      },
      "source": [
        "# Classifying Apropriate Assignment group based on Problem Description\n",
        "**Pradyun Magal, 2023 Summer**\n",
        "\n",
        "This Notebook takes you through the entire process of creating the model from start to finish\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8obYnLVvvbtt"
      },
      "source": [
        "# **Part 1**\n",
        "# *Installing Dependencies and Obtaining Data*\n",
        "\n",
        "Explained more in comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdE0J3qkujVG",
        "outputId": "00e76f7d-eae0-454a-a935-46f0334f5c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/6.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/6.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.14.0)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow_text)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow_text)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow_text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow_text-2.13.0 typing-extensions-4.5.0\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-08-08 01:25:21.702353: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-08-08 01:25:21.757686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-08 01:25:22.810768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install tensorflow_hub #For our BERT preprocessing\n",
        "!pip install spacy # For Name Entity Recognition\n",
        "!python -m spacy download en_core_web_lg # Used the large English library to increase accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itXj2F4MYCvE",
        "outputId": "d9705845-eb22-4ea9-8ec6-dca18219537c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "#Install and Import Libraries\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra toolkit\n",
        "import matplotlib.pyplot as plt\n",
        "import re # Data Cleaning\n",
        "import spacy\n",
        "spc = spacy.load(\"en_core_web_lg\") # For NER detection and data cleaning\n",
        "from spacy import displacy\n",
        "from bs4 import BeautifulSoup # For text parsing\n",
        "import tensorflow as tf # The ML Library I will be using to create NN\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "# ^ This set of lines is for debugging purposes to make sure that tensorflow can\n",
        "#   recognize the GPU on Colab\n",
        "from tensorflow import keras # Layers for NN\n",
        "import tensorflow_hub as hub # Dependencies Needed for BERT encoder\n",
        "import tensorflow_text as text\n",
        "from sklearn import preprocessing # For Label Encoding\n",
        "from sklearn.model_selection import train_test_split # For Splitting Data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiHx4lJ50U7X"
      },
      "source": [
        "**Convert From CSV to DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjvUPiDYZGHp",
        "outputId": "3878cd1c-e112-4d3c-fb66-b1069f13dbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29356 entries, 0 to 29355\n",
            "Data columns (total 29 columns):\n",
            " #   Column                        Non-Null Count  Dtype \n",
            "---  ------                        --------------  ----- \n",
            " 0   ID                            29356 non-null  int64 \n",
            " 1   Open DateTime                 29356 non-null  object\n",
            " 2   Ticket Id                     29356 non-null  object\n",
            " 3   Title                         27157 non-null  object\n",
            " 4   Description                   29350 non-null  object\n",
            " 5   Staff Name                    29356 non-null  object\n",
            " 6   Close DateTime                26872 non-null  object\n",
            " 7   Expected Response DateTime    29356 non-null  object\n",
            " 8   Expected Resolution DateTime  29356 non-null  object\n",
            " 9   Response Violated             29356 non-null  bool  \n",
            " 10  Response Violation Reason     171 non-null    object\n",
            " 11  Resolution Violated           29356 non-null  bool  \n",
            " 12  Resolution Violation Reason   434 non-null    object\n",
            " 13  Responded DateTime            29355 non-null  object\n",
            " 14  Resolved DateTime             29089 non-null  object\n",
            " 15  Resolution Comments           29089 non-null  object\n",
            " 16  Location Name                 29356 non-null  object\n",
            " 17  Classification                29356 non-null  object\n",
            " 18  Company                       29356 non-null  object\n",
            " 19  Department                    29356 non-null  object\n",
            " 20  Service Category              29356 non-null  object\n",
            " 21  Call Status                   29356 non-null  object\n",
            " 22  Group                         29356 non-null  object\n",
            " 23  Priority                      29356 non-null  object\n",
            " 24  Asset No                      23572 non-null  object\n",
            " 25  FM Age                        29356 non-null  int64 \n",
            " 26  CallClosure Description       19876 non-null  object\n",
            " 27  CallAgeHours                  29356 non-null  object\n",
            " 28  Reopen Ticket                 1879 non-null   object\n",
            "dtypes: bool(2), int64(2), object(25)\n",
            "memory usage: 6.1+ MB\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# Bring in our CSV File from the drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/GMSCRFDump.csv\", encoding=\"windows-1252\", encoding_errors=\"replace\")\n",
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBLkBdKA0Lj3"
      },
      "source": [
        "**Gather Columns We Need**\n",
        "\n",
        "In this case, Description is our Feature and Group is our Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LKi3mVG0E6o",
        "outputId": "286b711a-c72d-4ec7-916c-c2250809e8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29356 entries, 0 to 29355\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Description  29350 non-null  object\n",
            " 1   Group        29356 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 458.8+ KB\n"
          ]
        }
      ],
      "source": [
        "mainDf = df[[\"Description\",\"Group\"]]\n",
        "mainDf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjdTBdVw2CiL"
      },
      "source": [
        "# **Part 2**\n",
        "# *Begin Data Prep*\n",
        "\n",
        "*Includes splitting, cleaning and sorting of our data set*\n",
        "\n",
        "I also analyze dataset for things like imbalances and biases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "QBrx7vQj2Iz6",
        "outputId": "47199d2f-97a7-43a0-d134-ca19fcf02e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 29350 entries, 0 to 29355\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Description  29350 non-null  object\n",
            " 1   Group        29350 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 687.9+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Description             Group\n",
              "0  Kindly Provide Bookmark Access to Below User a...  MESSAGING DOMINO\n",
              "1  KIndly add user ID in Ludhiana RO & Ludhiana G...  MESSAGING DOMINO\n",
              "2  Kindly Provide Bookmark Access For Freelook Ca...  MESSAGING DOMINO\n",
              "3  Please add user in all HO & GO group. Vaibhav ...  MESSAGING DOMINO\n",
              "4  to please modify (Add & Delete) some ID form d...  MESSAGING DOMINO"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7be88acf-ab12-4269-a78c-04b24545dc87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kindly Provide Bookmark Access to Below User a...</td>\n",
              "      <td>MESSAGING DOMINO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KIndly add user ID in Ludhiana RO &amp; Ludhiana G...</td>\n",
              "      <td>MESSAGING DOMINO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kindly Provide Bookmark Access For Freelook Ca...</td>\n",
              "      <td>MESSAGING DOMINO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please add user in all HO &amp; GO group. Vaibhav ...</td>\n",
              "      <td>MESSAGING DOMINO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to please modify (Add &amp; Delete) some ID form d...</td>\n",
              "      <td>MESSAGING DOMINO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7be88acf-ab12-4269-a78c-04b24545dc87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-20150f89-6689-488c-ab5e-5427972dc35e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20150f89-6689-488c-ab5e-5427972dc35e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-20150f89-6689-488c-ab5e-5427972dc35e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7be88acf-ab12-4269-a78c-04b24545dc87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7be88acf-ab12-4269-a78c-04b24545dc87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ],
      "source": [
        "# Start off by simply dropping Null Rows\n",
        "mainDf = mainDf.dropna()\n",
        "mainDf.info()\n",
        "mainDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7a2Ps5R0oac"
      },
      "source": [
        "As we can see from Before, there's not a lot of NULL rows. This means we can safley remove null values and it won't have a huge effect on the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f48snkxF3B7O"
      },
      "source": [
        "**Data Imbalance**\n",
        "\n",
        "We noticed that there's a huge imbalance present in the spread of Data as seen below. There are some labels in the dataset that make up less than 0.005% of the total data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hSBP9kzA6GL",
        "outputId": "d4faec5c-f081-4665-d36f-40cbeed623e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I-Prompt                       9229\n",
            "SERVER MANAGEMENT              5031\n",
            "MESSAGING DOMINO               3116\n",
            "DB MANAGEMENT - ORACLE         3022\n",
            "SECURITY MANAGEMENT            1978\n",
            "Server Management - AIX        1287\n",
            "STORAGE SUPPORT                1098\n",
            "Server Management - Linux       974\n",
            "DB MANAGEMENT - SQL             941\n",
            "BACKUP MANAGEMENT               808\n",
            "NETWORK MANAGEMENT              562\n",
            "Server Management-AVPM          472\n",
            "Infosec                         311\n",
            "Server Management - SOLARIS     228\n",
            "SERVER MANAGEMENT - UNIX        183\n",
            "AS400                            38\n",
            "SIM ANALYSIS                     33\n",
            "MLIC                             26\n",
            "DB2 - DATABASE                   13\n",
            "Name: Group, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(mainDf[\"Group\"].value_counts())\n",
        "# Look at how dataset balance affects accuracy, eg most common labels bias model\n",
        "# Network Management and Below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLS2tloPU_Vq"
      },
      "source": [
        "With this in mind, we decied to do the following so that we don't let labels that show up very infrequently affecy our results:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        " - Labels with 1000+ Appearances stays in main Model\n",
        " - Labels < 1000 Appearances Goes into a \"Mini\" or smaller model\n",
        " - Labels with < 100 Appearances Gets Dropped Completley\n",
        "\n",
        " We Will also be removing around 40% random rows in I-Prompt and saving them in another dataframe for testing.\n",
        "```\n",
        "\n",
        "The following ruleset above means we need to split our data into two different Datasets, I chose the names `mainDf` and `miniD` for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRDOcOM_ftqh"
      },
      "outputs": [],
      "source": [
        "# First we drop all the excess rows in I-Prompt, save it to ipromptDf\n",
        "ipromptDf = mainDf[mainDf[\"Group\"] == 'I-Prompt'].sample(frac=.4)\n",
        "mainDf = mainDf.drop(ipromptDf.index,inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cf8COdf797uO",
        "outputId": "c1e9d8b0-96e7-4435-9d87-40a1e0e3f389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Description     Group\n",
              "3470   Call logged by Iprompt for the task :: 'Need t...  I-Prompt\n",
              "20171  Call logged by Iprompt for the task :: 'SAN Sw...  I-Prompt\n",
              "24966  Call logged by Iprompt for the task :: 'Need t...  I-Prompt\n",
              "6771   Call logged by Iprompt for the task :: 'Need t...  I-Prompt\n",
              "25017  Call logged by Iprompt for the task :: 'Need t...  I-Prompt"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-773edbec-b85e-4750-9392-f7a9834cd8bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3470</th>\n",
              "      <td>Call logged by Iprompt for the task :: 'Need t...</td>\n",
              "      <td>I-Prompt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20171</th>\n",
              "      <td>Call logged by Iprompt for the task :: 'SAN Sw...</td>\n",
              "      <td>I-Prompt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24966</th>\n",
              "      <td>Call logged by Iprompt for the task :: 'Need t...</td>\n",
              "      <td>I-Prompt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6771</th>\n",
              "      <td>Call logged by Iprompt for the task :: 'Need t...</td>\n",
              "      <td>I-Prompt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25017</th>\n",
              "      <td>Call logged by Iprompt for the task :: 'Need t...</td>\n",
              "      <td>I-Prompt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-773edbec-b85e-4750-9392-f7a9834cd8bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f61bab73-4b54-4177-92e7-15390b920194\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f61bab73-4b54-4177-92e7-15390b920194')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f61bab73-4b54-4177-92e7-15390b920194 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-773edbec-b85e-4750-9392-f7a9834cd8bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-773edbec-b85e-4750-9392-f7a9834cd8bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ipromptDf.head() # Just to see what it looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6BUsh3CRg5U",
        "outputId": "9f367f5b-df36-497d-c000-99852662be5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server Management - Linux      974\n",
            "DB MANAGEMENT - SQL            941\n",
            "BACKUP MANAGEMENT              808\n",
            "NETWORK MANAGEMENT             562\n",
            "Server Management-AVPM         472\n",
            "Infosec                        311\n",
            "Server Management - SOLARIS    228\n",
            "SERVER MANAGEMENT - UNIX       183\n",
            "Name: Group, dtype: int64\n",
            "I-Prompt                       5537\n",
            "SERVER MANAGEMENT              5031\n",
            "MESSAGING DOMINO               3116\n",
            "DB MANAGEMENT - ORACLE         3022\n",
            "SECURITY MANAGEMENT            1978\n",
            "Server Management - AIX        1287\n",
            "STORAGE SUPPORT                1098\n",
            "Server Management - Linux       974\n",
            "DB MANAGEMENT - SQL             941\n",
            "BACKUP MANAGEMENT               808\n",
            "NETWORK MANAGEMENT              562\n",
            "Server Management-AVPM          472\n",
            "Infosec                         311\n",
            "Server Management - SOLARIS     228\n",
            "SERVER MANAGEMENT - UNIX        183\n",
            "Name: Group, dtype: int64\n",
            "4479\n",
            "25548\n"
          ]
        }
      ],
      "source": [
        "includeList = [\"Server Management - Linux\",\"DB MANAGEMENT - SQL\",\"BACKUP MANAGEMENT\",\"NETWORK MANAGEMENT\",\"Server Management-AVPM\",\"Infosec\",\"Server Management - SOLARIS\",\"SERVER MANAGEMENT - UNIX\"]\n",
        "excludeList = [\"AS400\",\"SIM ANALYSIS\",\"MLIC\",\"DB2 - DATABASE\"]\n",
        "miniDf = mainDf[mainDf[\"Group\"].isin(includeList)] # Mini DF includes whatever is in the list\n",
        "mainDf = mainDf[~mainDf[\"Group\"].isin(excludeList)] # Main Df drops the labels we tell it to\n",
        "print(miniDf[\"Group\"].value_counts())\n",
        "print(mainDf[\"Group\"].value_counts())\n",
        "print(len(miniDf)) # This value will match with the submodel length (later lines below)\n",
        "print(len(mainDf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnZZY8bML_LT",
        "outputId": "9f31e05a-b91c-4cb6-ca3a-4153799353df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Server Management - Linux': 'submodel', 'DB MANAGEMENT - SQL': 'submodel', 'BACKUP MANAGEMENT': 'submodel', 'NETWORK MANAGEMENT': 'submodel', 'Server Management-AVPM': 'submodel', 'Infosec': 'submodel', 'Server Management - SOLARIS': 'submodel', 'SERVER MANAGEMENT - UNIX': 'submodel'}\n",
            "I-Prompt                   5537\n",
            "SERVER MANAGEMENT          5031\n",
            "submodel                   4479\n",
            "MESSAGING DOMINO           3116\n",
            "DB MANAGEMENT - ORACLE     3022\n",
            "SECURITY MANAGEMENT        1978\n",
            "Server Management - AIX    1287\n",
            "STORAGE SUPPORT            1098\n",
            "Name: Group, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Adjust all of the labels\n",
        "rDict = dict.fromkeys(includeList, \"submodel\")\n",
        "print(rDict)\n",
        "mainDf = mainDf.replace(rDict)\n",
        "print(mainDf[\"Group\"].value_counts())\n",
        "# 4479 In submodel, which is the total amount in miniDf meaning the split was successful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Bh5o0_MGgz"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYJMDO8kW5S9"
      },
      "source": [
        "We need to convert our `str` label classes into numerical categories, easiest way to do this with a pandas dataframe is using sklearn's `preprocessing` library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNisBdW3VqW",
        "outputId": "575dec47-f693-43e6-c92a-266e443c4a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MESSAGING DOMINO' 'SERVER MANAGEMENT' 'submodel' 'STORAGE SUPPORT'\n",
            " 'Server Management - AIX' 'I-Prompt' 'SECURITY MANAGEMENT'\n",
            " 'DB MANAGEMENT - ORACLE']\n",
            "[2 4 7 5 6 1 3 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "nameList = list(mainDf[\"Group\"].unique()) # We will use this list to form a dictionary from where we can conver the number label to the string label\n",
        "print(mainDf[\"Group\"].unique())\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "mainDf[\"Group\"] = label_encoder.fit_transform(mainDf[\"Group\"]) # Encodes the Group column\n",
        "encodeList = list(mainDf[\"Group\"].unique()) # Obtain the unique values after encoding\n",
        "print(mainDf[\"Group\"].unique())\n",
        "deDict = dict(zip(encodeList, nameList))\n",
        "# deDict is correct, because according to pandas the unqiue() function returns values in order of apperance;\n",
        "# And since we didn't adjust the order of the frame we know it is correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeS9lxjSYMvV"
      },
      "source": [
        "Below I did the same process on the `miniDf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsvJhMEuRvMD",
        "outputId": "34f8e276-cfaf-4550-e916-21059202f946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 1 3 0 2 6 7 4]\n",
            "{5: 'Server Management - Linux', 1: 'DB MANAGEMENT - SQL', 3: 'NETWORK MANAGEMENT', 0: 'BACKUP MANAGEMENT', 2: 'Infosec', 6: 'Server Management - SOLARIS', 7: 'Server Management-AVPM', 4: 'SERVER MANAGEMENT - UNIX'}\n"
          ]
        }
      ],
      "source": [
        "# Encode the miniDF\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "miniNameList = list(miniDf[\"Group\"].unique())\n",
        "miniDf[\"Group\"] = label_encoder.fit_transform(miniDf[\"Group\"])\n",
        "miniEncodeList = list(miniDf[\"Group\"].unique())\n",
        "print(miniDf[\"Group\"].unique())\n",
        "miniDict = dict(zip(miniEncodeList, miniNameList))\n",
        "print(miniDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1d0Me1J-bg7"
      },
      "outputs": [],
      "source": [
        "ipromptDf[\"Group\"] = 1\n",
        "# The following line will make all labels 1 which is the encoding for iPrompt in the mainDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVU8kS9y52xr",
        "outputId": "e440bdd0-84d7-4f88-ac4a-7dd8d6a615ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2: 'MESSAGING DOMINO', 4: 'SERVER MANAGEMENT', 7: 'submodel', 5: 'STORAGE SUPPORT', 6: 'Server Management - AIX', 1: 'I-Prompt', 3: 'SECURITY MANAGEMENT', 0: 'DB MANAGEMENT - ORACLE'}\n",
            "1    5537\n",
            "4    5031\n",
            "7    4479\n",
            "2    3116\n",
            "0    3022\n",
            "3    1978\n",
            "6    1287\n",
            "5    1098\n",
            "Name: Group, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(deDict)\n",
        "print(mainDf[\"Group\"].value_counts())\n",
        "# This cell is just for debugging, but it gives us further reassurance that the labels are correct. I-Prompt is still the highest appearnce for example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it9llbMgXJ_B"
      },
      "source": [
        "**Text Cleaning**\n",
        "\n",
        "I experminted around with many cleaning strategies including:\n",
        "\n",
        "*   Regex removal of special character\n",
        "*   Regex replacement of certain characters with spaces\n",
        "*   Parsing with Beautiful Soup Module to bring out text from any potential\n",
        "HTML\n",
        "* Removal of Stopwords from NLTK library\n",
        "\n",
        "All of the above were done in attempts to make it easier for the [Tensorflow BERT Encoder](https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1) to tokenize the words. The idea is removing any uneeded characters that can throw off the encodings, for example we don't want the model to thing '/' or '@' has something to do with the final encoding.\n",
        "But after lots of trial and error we figured we would let the [BERT Preprocess Model on TF Hub](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3) do the work for us, and remove any Names in the tickets instead.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMld_cpg3v4i"
      },
      "outputs": [],
      "source": [
        "def removeWeirdCharacters(text):\n",
        "    # soup = BeautifulSoup(text,\"html.parser\")\n",
        "    # text = soup.get_text()\n",
        "    doc = spc(text)\n",
        "    newText = text\n",
        "    for word in doc.ents:\n",
        "        if word.label_ == \"PERSON\":\n",
        "            newText = newText.replace(word.text,'')\n",
        "    text = newText\n",
        "    # text = re.sub(r\"[()@.,-]+\",'',text)\n",
        "    # text = re.sub(r\"[&;:/]\",' ',text)\n",
        "    # text = re.sub(r\"\\d\",'',text)\n",
        "    # stop_words = set(stopwords.words('english'))\n",
        "    # word_tokens = word_tokenize(text)\n",
        "    # filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    # text = ' '.join(filtered_sentence)\n",
        "    text = text.lower()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARYHyUutc1oo"
      },
      "source": [
        "As seen above, I left all of the initial attempts of cleaning the text data by hand as comments. It is a little harder to read but serves as a reminder forn me personally as to what methods I've tried."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS77Wu2i6B7D"
      },
      "outputs": [],
      "source": [
        "mainDf[\"Description\"] = mainDf[\"Description\"].apply(removeWeirdCharacters)\n",
        "miniDf[\"Description\"] = miniDf[\"Description\"].apply(removeWeirdCharacters)\n",
        "ipromptDf[\"Description\"] = ipromptDf[\"Description\"].apply(removeWeirdCharacters)\n",
        "# Apply the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cJ8nOwNaV03",
        "outputId": "c1617669-cf9c-4909-802e-81f85b595225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Description  Group\n",
            "0  kindly provide bookmark access to below user a...      2\n",
            "1  kindly add user id in ludhiana ro & ludhiana g...      2\n",
            "2  kindly provide bookmark access for freelook ca...      2\n",
            "3  please add user in all ho & go group.  (emp id...      2\n",
            "4  to please modify (add & delete) some id form d...      2\n",
            "increase mail quota size for below user. ad2835 \n",
            "---------------------\n",
            "                                           Description  Group\n",
            "68   kindly provide server right for below user ser...      5\n",
            "70   kindly replicate all the db access from aj2929...      1\n",
            "71   please provide the structure of view name -- v...      1\n",
            "72   need to execute dbcc checkdb on gursrv0345 ser...      1\n",
            "144  kindly enable the ports and ether channel cabl...      3\n",
            "kindly replicate all the db access from aj29296 to os42439. \n"
          ]
        }
      ],
      "source": [
        "print(mainDf.head())\n",
        "print(mainDf[\"Description\"][100])\n",
        "print(\"---------------------\")\n",
        "print(miniDf.head())\n",
        "print(miniDf[\"Description\"][70])\n",
        "# See roughly what the cleaning looks like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwHkAn2uftAP"
      },
      "source": [
        "**Data Splitting**\n",
        "\n",
        "Simply used sklearn's `train_test_split` function on both `mainDf` and `miniDf`\n",
        "Made sure to use `stratify` in order to make the best use of randomizing the order and splitting as cleanly as possible. We want to make sure we test and train our model on data it's never seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck_8OSC9VfWF",
        "outputId": "a60580f0-d8c4-475d-963c-e2bea189daa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTS\n",
            "19161\n",
            "19161\n",
            "6387\n",
            "6387\n",
            "MINIS\n",
            "3359\n",
            "3359\n",
            "1120\n",
            "1120\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train, x_test, Y_train, y_test = train_test_split(mainDf['Description'],mainDf[\"Group\"], stratify=mainDf[\"Group\"])\n",
        "miniX_train, minix_test, miniY_train, miniy_test = train_test_split(miniDf['Description'],miniDf[\"Group\"], stratify=miniDf[\"Group\"])\n",
        "# The following test are to make sure everything is proper, the x and ys for both trains and tests need to be the same length\n",
        "print(\"TESTS\")\n",
        "print(len(X_train))\n",
        "print(len(Y_train))\n",
        "print(len(x_test))\n",
        "print(len(y_test))\n",
        "print(\"MINIS\")\n",
        "print(len(miniX_train))\n",
        "print(len(miniY_train))\n",
        "print(len(minix_test))\n",
        "print(len(miniy_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QLAO7U4hYeH"
      },
      "source": [
        "Let's have a look at the series created from the split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xdKNW-29wVI",
        "outputId": "c04c1e08-902d-46d2-b3cc-e5ef7fa31c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26924    backup team : kindly confirm the latest tape b...\n",
            "22971    vlingursrv0651, vm tools not installed, so ple...\n",
            "7033     backup team : kindly confirm the latest tape b...\n",
            "6826     kindly activate the 1 lan port . loginid mkptn...\n",
            "26023    kindly share the below details asap 1. current...\n",
            "Name: Description, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(miniX_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0D5CaiFiWKH"
      },
      "source": [
        "**One Hot Encoding**\n",
        "Since Tensorflow uses Keras layers to form a model, I needed to one hot encode the data so that it can be passed into the neural network.\n",
        "The loss function I used for the neural network was Keras's [CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) which requires data be sent in via one hot encoding\n",
        "\n",
        "I used pandas `get_dummies` as a means of one hot encoding the categorixal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhNcOubsoGGM",
        "outputId": "71898bfd-15cf-48ed-cc2d-2424a689d5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19161\n",
            "3359\n"
          ]
        }
      ],
      "source": [
        "newytrain = pd.get_dummies(Y_train, prefix='group')\n",
        "print(len(newytrain)) # Just to make sure\n",
        "unhotytrain = Y_train # For analysis and testing, I made sure to keep copies of the dataframe columns before they were one hot encoded to be safe\n",
        "Y_train = newytrain\n",
        "\n",
        "newminiytrain = pd.get_dummies(miniY_train,prefix='group')\n",
        "print(len(newminiytrain)) # Can never be too safe\n",
        "miniytrainnohot = miniY_train\n",
        "miniY_train = newminiytrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_gmZACekXfd"
      },
      "source": [
        "Same thing on the Test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jumKoG1fUl_F"
      },
      "outputs": [],
      "source": [
        "#test splits\n",
        "newytest = pd.get_dummies(y_test, prefix='group')\n",
        "unhotytest = y_test\n",
        "y_test = newytest\n",
        "\n",
        "mininewytest = pd.get_dummies(miniy_test, prefix='group')\n",
        "miniunhotytest = miniy_test\n",
        "miniy_test = mininewytest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htUYPvf_XfZo",
        "outputId": "16129ac5-178d-4144-a425-3eda21e60f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       group_0  group_1  group_2  group_3  group_4  group_5  group_6  group_7\n",
            "26924        1        0        0        0        0        0        0        0\n",
            "22971        0        0        0        0        0        1        0        0\n",
            "7033         1        0        0        0        0        0        0        0\n",
            "6826         0        0        0        1        0        0        0        0\n",
            "26023        0        0        0        0        0        0        1        0\n"
          ]
        }
      ],
      "source": [
        "print(miniY_train.head()) # Seeing what our result looks like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1DApLfjkbzP"
      },
      "source": [
        "# **The Nueral Network**\n",
        "# *Building and Training it*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFxamxqkote"
      },
      "source": [
        "The first two layers will be to handle text, it goes through `bert_preprocess` and `bert_encoder` in order to first get the text tokenized so that it can be processed by the rest of the model.\n",
        "It then goes through a dropout layer just to prevent overfitting, the dropout layer is very sparse but necessary.\n",
        "And the final and most important layer is the `Keras.dense` layer that uses a sigmoid function for activation.\n",
        "This layer has as many nuerons as there are labels to predict, in the case of both the mini model and the main model there are 8 label classes.\n",
        "\n",
        "The returned result is an array of 8 different probability values, the highest being the overall prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MEjOfm_ujVt"
      },
      "outputs": [],
      "source": [
        "#What nn Would Look like:\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "#Inputs\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "#Heart of NN\n",
        "l = tf.keras.layers.Dropout(0.02, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(8, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoNm4c9gnHuh"
      },
      "source": [
        "Same for the mini model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGD0PmKrU5m4"
      },
      "outputs": [],
      "source": [
        "#mini model\n",
        "bert_preprocess2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "#Inputs\n",
        "text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text2 = bert_preprocess2(text_input2)\n",
        "outputs2 = bert_encoder2(preprocessed_text2)\n",
        "\n",
        "#Heart of NN\n",
        "l2 = tf.keras.layers.Dropout(0.01, name=\"dropout\")(outputs2['pooled_output'])\n",
        "l2 = tf.keras.layers.Dense(8, activation='sigmoid', name=\"output\")(l2)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "minimodel = tf.keras.Model(inputs=[text_input2], outputs = [l2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdgF0_PBzcuN",
        "outputId": "bc3b56f8-5e80-4445-bf26-e567a9838b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)    {'input_word_ids': (None,    0         ['text[0][0]']                \n",
            "                             128),                                                                \n",
            "                              'input_type_ids': (None,                                            \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             }                                                                    \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)  {'sequence_output': (None,   1094822   ['keras_layer[0][0]',         \n",
            "                              128, 768),                  41         'keras_layer[0][1]',         \n",
            "                              'pooled_output': (None, 7              'keras_layer[0][2]']         \n",
            "                             68),                                                                 \n",
            "                              'default': (None, 768),                                             \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)]}                                                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 8)                    6152      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109488393 (417.67 MB)\n",
            "Trainable params: 6152 (24.03 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)  {'input_mask': (None, 128)   0         ['text[0][0]']                \n",
            "                             , 'input_type_ids': (None,                                           \n",
            "                              128),                                                               \n",
            "                              'input_word_ids': (None,                                            \n",
            "                             128)}                                                                \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)  {'sequence_output': (None,   1094822   ['keras_layer_2[0][0]',       \n",
            "                              128, 768),                  41         'keras_layer_2[0][1]',       \n",
            "                              'default': (None, 768),                'keras_layer_2[0][2]']       \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'pooled_output': (None, 7                                           \n",
            "                             68)}                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 768)                  0         ['keras_layer_3[0][13]']      \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 8)                    6152      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109488393 (417.67 MB)\n",
            "Trainable params: 6152 (24.03 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())\n",
        "print(minimodel.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPgu5qYnncTz"
      },
      "source": [
        "**Metrics**\n",
        "\n",
        "For the metrics I decided to go with:\n",
        "*   Categorical Accuracy to see how good the model is at overall predicting\n",
        "*   Precision to see how consistent the model is at predicting particular classes\n",
        "* Recall to give us a good idea of the ratio between false positives and negatives\n",
        "\n",
        "I compiled the models with the `adam` optimizer as this seemingly is the most popular."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPjF-6YutiNU"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=METRICS)\n",
        "\n",
        "minimodel.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1trk4LFbokad"
      },
      "source": [
        "This is where the waiting game starts, I decided to start with 30 Epochs on the main model and 25 on the mini, and see how much I needed to add afterwards.\n",
        "\n",
        "It is tricky to not overtrain the model in hopes of maximizing accuracy as theres usually an apropriate treshold of epochs that one has to find via experimenting.\n",
        "\n",
        "Final Amount of epochs:\n",
        "\n",
        "Main 45\n",
        "\n",
        "Mini 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MUZMDnH2bY0",
        "outputId": "8ceb9814-c2fd-41ec-8a07-0cc840c59594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "599/599 [==============================] - 93s 134ms/step - loss: 1.2981 - accuracy: 0.5139 - precision: 0.2162 - recall: 0.9251\n",
            "Epoch 2/30\n",
            "599/599 [==============================] - 83s 139ms/step - loss: 1.1411 - accuracy: 0.5756 - precision: 0.2253 - recall: 0.9537\n",
            "Epoch 3/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 1.0716 - accuracy: 0.6064 - precision: 0.2320 - recall: 0.9575\n",
            "Epoch 4/30\n",
            "599/599 [==============================] - 84s 140ms/step - loss: 1.0243 - accuracy: 0.6236 - precision: 0.2370 - recall: 0.9581\n",
            "Epoch 5/30\n",
            "599/599 [==============================] - 81s 135ms/step - loss: 0.9898 - accuracy: 0.6368 - precision: 0.2411 - recall: 0.9610\n",
            "Epoch 6/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.9706 - accuracy: 0.6431 - precision: 0.2448 - recall: 0.9611\n",
            "Epoch 7/30\n",
            "599/599 [==============================] - 80s 134ms/step - loss: 0.9514 - accuracy: 0.6493 - precision: 0.2465 - recall: 0.9643\n",
            "Epoch 8/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.9311 - accuracy: 0.6559 - precision: 0.2493 - recall: 0.9628\n",
            "Epoch 9/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.9201 - accuracy: 0.6581 - precision: 0.2520 - recall: 0.9643\n",
            "Epoch 10/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.9097 - accuracy: 0.6632 - precision: 0.2536 - recall: 0.9641\n",
            "Epoch 11/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8953 - accuracy: 0.6703 - precision: 0.2555 - recall: 0.9633\n",
            "Epoch 12/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8913 - accuracy: 0.6669 - precision: 0.2558 - recall: 0.9636\n",
            "Epoch 13/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8776 - accuracy: 0.6795 - precision: 0.2583 - recall: 0.9649\n",
            "Epoch 14/30\n",
            "599/599 [==============================] - 79s 132ms/step - loss: 0.8737 - accuracy: 0.6749 - precision: 0.2588 - recall: 0.9632\n",
            "Epoch 15/30\n",
            "599/599 [==============================] - 79s 132ms/step - loss: 0.8679 - accuracy: 0.6786 - precision: 0.2605 - recall: 0.9648\n",
            "Epoch 16/30\n",
            "599/599 [==============================] - 79s 132ms/step - loss: 0.8639 - accuracy: 0.6782 - precision: 0.2609 - recall: 0.9647\n",
            "Epoch 17/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8498 - accuracy: 0.6858 - precision: 0.2624 - recall: 0.9668\n",
            "Epoch 18/30\n",
            "599/599 [==============================] - 80s 134ms/step - loss: 0.8476 - accuracy: 0.6867 - precision: 0.2625 - recall: 0.9677\n",
            "Epoch 19/30\n",
            "599/599 [==============================] - 79s 133ms/step - loss: 0.8456 - accuracy: 0.6897 - precision: 0.2636 - recall: 0.9655\n",
            "Epoch 20/30\n",
            "599/599 [==============================] - 81s 134ms/step - loss: 0.8436 - accuracy: 0.6884 - precision: 0.2634 - recall: 0.9652\n",
            "Epoch 21/30\n",
            "599/599 [==============================] - 81s 135ms/step - loss: 0.8375 - accuracy: 0.6879 - precision: 0.2641 - recall: 0.9684\n",
            "Epoch 22/30\n",
            "599/599 [==============================] - 81s 134ms/step - loss: 0.8313 - accuracy: 0.6915 - precision: 0.2633 - recall: 0.9666\n",
            "Epoch 23/30\n",
            "599/599 [==============================] - 81s 135ms/step - loss: 0.8319 - accuracy: 0.6927 - precision: 0.2641 - recall: 0.9669\n",
            "Epoch 24/30\n",
            "599/599 [==============================] - 81s 135ms/step - loss: 0.8285 - accuracy: 0.6911 - precision: 0.2643 - recall: 0.9668\n",
            "Epoch 25/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8235 - accuracy: 0.6956 - precision: 0.2645 - recall: 0.9671\n",
            "Epoch 26/30\n",
            "599/599 [==============================] - 80s 134ms/step - loss: 0.8169 - accuracy: 0.6973 - precision: 0.2651 - recall: 0.9674\n",
            "Epoch 27/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8167 - accuracy: 0.6972 - precision: 0.2651 - recall: 0.9684\n",
            "Epoch 28/30\n",
            "599/599 [==============================] - 80s 134ms/step - loss: 0.8105 - accuracy: 0.6999 - precision: 0.2648 - recall: 0.9682\n",
            "Epoch 29/30\n",
            "599/599 [==============================] - 80s 133ms/step - loss: 0.8133 - accuracy: 0.6987 - precision: 0.2650 - recall: 0.9665\n",
            "Epoch 30/30\n",
            "599/599 [==============================] - 80s 134ms/step - loss: 0.8050 - accuracy: 0.6995 - precision: 0.2652 - recall: 0.9697\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x789c8a6447c0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ffYYbYyXbp4",
        "outputId": "8cb73e17-8ad7-480d-8f75-e6a90536cec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "105/105 [==============================] - 22s 135ms/step - loss: 1.7359 - accuracy: 0.6499 - precision: 0.2505 - recall: 0.9536\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.5404 - accuracy: 0.4665 - precision: 0.2006 - recall: 0.8943\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.4405 - accuracy: 0.4993 - precision: 0.2141 - recall: 0.9047\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.3722 - accuracy: 0.5252 - precision: 0.2180 - recall: 0.9113\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.3203 - accuracy: 0.5561 - precision: 0.2248 - recall: 0.9137\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.2951 - accuracy: 0.5537 - precision: 0.2305 - recall: 0.9128\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.2578 - accuracy: 0.5761 - precision: 0.2333 - recall: 0.9107\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.2198 - accuracy: 0.5915 - precision: 0.2347 - recall: 0.9116\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.2031 - accuracy: 0.5915 - precision: 0.2387 - recall: 0.9196\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.1808 - accuracy: 0.6115 - precision: 0.2461 - recall: 0.9149\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.1530 - accuracy: 0.6174 - precision: 0.2478 - recall: 0.9208\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 15s 139ms/step - loss: 1.1316 - accuracy: 0.6320 - precision: 0.2522 - recall: 0.9244\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.1200 - accuracy: 0.6326 - precision: 0.2540 - recall: 0.9223\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.1078 - accuracy: 0.6392 - precision: 0.2557 - recall: 0.9202\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.0836 - accuracy: 0.6422 - precision: 0.2592 - recall: 0.9235\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.0882 - accuracy: 0.6451 - precision: 0.2587 - recall: 0.9199\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0643 - accuracy: 0.6576 - precision: 0.2640 - recall: 0.9241\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0467 - accuracy: 0.6591 - precision: 0.2653 - recall: 0.9288\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 14s 135ms/step - loss: 1.0366 - accuracy: 0.6651 - precision: 0.2709 - recall: 0.9232\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0257 - accuracy: 0.6666 - precision: 0.2720 - recall: 0.9256\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0272 - accuracy: 0.6615 - precision: 0.2715 - recall: 0.9247\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0284 - accuracy: 0.6639 - precision: 0.2717 - recall: 0.9235\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 1.0007 - accuracy: 0.6761 - precision: 0.2791 - recall: 0.9256\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 14s 134ms/step - loss: 0.9881 - accuracy: 0.6835 - precision: 0.2791 - recall: 0.9324\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 14s 138ms/step - loss: 0.9848 - accuracy: 0.6862 - precision: 0.2782 - recall: 0.9315\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x789c893b7e20>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minimodel.fit(miniX_train,miniY_train,epochs=35)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59RiyjR8Uw3g",
        "outputId": "cd0c2ce1-5f21-40da-d26c-3d3330226d06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/MyDrive/PradyunfinNoNer5.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO-S6OFbU3HS"
      },
      "outputs": [],
      "source": [
        "minimodel.save(\"/content/drive/MyDrive/PradyufinMiniNoNer5.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAOCE9ktmMCV",
        "outputId": "2b62c235-29ad-4cdf-9273-7b6e46eb7e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 27s 137ms/step - loss: 0.8266 - accuracy: 0.6897 - precision: 0.2647 - recall: 0.9632\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.8266290426254272,\n",
              " 0.6896821856498718,\n",
              " 0.2646704614162445,\n",
              " 0.9632065296173096]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUxqygG9ar7r",
        "outputId": "6d320e82-60c6-4af0-bf2a-aef3725eb9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 5s 136ms/step - loss: 1.0200 - accuracy: 0.6634 - precision: 0.2816 - recall: 0.9152\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.0200402736663818,\n",
              " 0.6633928418159485,\n",
              " 0.2815934121608734,\n",
              " 0.9151785969734192]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minimodel.evaluate(minix_test,miniy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxdDOj2RkDb"
      },
      "source": [
        "# Diagnostics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_FVD5O2YLiA"
      },
      "source": [
        "Load Models made above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoYVejqCX_dB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "2f70520a-d03c-4269-b5cb-b78975ea349a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e71939f7dd7c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmainModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/PradyunfinNoNer10.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'KerasLayer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mminiModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/PradyufinMiniNoNer10.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'KerasLayer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     \u001b[0;34mf\" filepath={filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                                 )\n\u001b[0;32m--> 249\u001b[0;31m                             return hdf5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    250\u001b[0m                                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                 \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         model = model_config_lib.model_from_config(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0mtlco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_THREAD_LOCAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    498\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                     custom_objects={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3225\u001b[0m                 \u001b[0;31m# Revive Functional model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m                 \u001b[0;31m# (but not Functional subclasses with a custom __init__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m                 inputs, outputs, layers = functional.reconstruct_from_config(\n\u001b[0m\u001b[1;32m   3228\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m         )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     return serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# saved_model logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0min_tf_saved_model_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         return legacy_serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintable_module_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                     \u001b[0mdeserialized_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \"\"\"\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m           \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    118\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    119\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    856\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m    989\u001b[0m                         ckpt_options, options, filters)\n\u001b[1;32m    990\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     self._concrete_functions = (\n\u001b[0;32m--> 161\u001b[0;31m         function_deserialization.load_function_def_library(\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mlibrary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0msaved_object_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# import).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m       func_graph = function_def_lib.function_def_to_graph(\n\u001b[0m\u001b[1;32m    423\u001b[0m           \u001b[0mfdef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mstructured_input_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_input_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Add all function nodes to the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     importer.import_graph_def_for_function(\n\u001b[0m\u001b[1;32m     98\u001b[0m         graph_def, name=\"\", propagate_device_spec=propagate_device_spec)\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[0;34m(graph_def, name, propagate_device_spec)\u001b[0m\n\u001b[1;32m    415\u001b[0m     graph_def, name=None, propagate_device_spec=False):\n\u001b[1;32m    416\u001b[0m   \u001b[0;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m   return _import_graph_def_internal(\n\u001b[0m\u001b[1;32m    418\u001b[0m       \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       \u001b[0mvalidate_colocation_constraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list, propagate_device_spec)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;31m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0m_ProcessNewOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_ProcessNewOps\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0mcolocation_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mnew_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_new_tf_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0moriginal_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_add_new_tf_operations\u001b[0;34m(self, compute_devices)\u001b[0m\n\u001b[1;32m   3530\u001b[0m     \u001b[0;31m# Create all Operation objects before accessing their inputs since an op may\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m     \u001b[0;31m# be created before its inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m     new_ops = [\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3531\u001b[0m     \u001b[0;31m# be created before its inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3532\u001b[0m     new_ops = [\n\u001b[0;32m-> 3533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_from_tf_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_from_tf_operation\u001b[0;34m(self, c_op, compute_device)\u001b[0m\n\u001b[1;32m   3413\u001b[0m     \"\"\"\n\u001b[1;32m   3414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3415\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_c_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3416\u001b[0m     \u001b[0;31m# If a name_scope was created with ret.name but no nodes were created in it,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3417\u001b[0m     \u001b[0;31m# the name will still appear in _names_in_use even though the name hasn't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_from_c_op\u001b[0;34m(cls, c_op, g)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \"\"\"\n\u001b[1;32m   1920\u001b[0m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraphTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m   1936\u001b[0m     \u001b[0;31m# context managers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_code_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[0;31m# Gradient function for this op. There are three ways to specify gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_control_flow_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m     \"\"\"Returns the current control flow context.\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mainModel = tf.keras.models.load_model(\"/content/drive/MyDrive/PradyunfinNoNer11.h5\",custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "miniModel = tf.keras.models.load_model(\"/content/drive/MyDrive/PradyufinMiniNoNer11.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "miniModel.save(\"/content/drive/MyDrive/PradyufinMiniNoNer11.h5\")"
      ],
      "metadata": {
        "id": "MFgfcbRaFCvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mainModel.save(\"/content/drive/MyDrive/PradyunfinNoNer11.h5\")"
      ],
      "metadata": {
        "id": "HLWMA4Hxq8RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GapW-1y6giqx"
      },
      "source": [
        "Run Metrics on Larger Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpUlx15RfjDG",
        "outputId": "db825889-ecf2-4904-b4f5-4731d3084d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 13s 64ms/step\n"
          ]
        }
      ],
      "source": [
        "newy_test = y_test.reset_index(inplace=False,drop=True)\n",
        "newx_test = x_test.reset_index(inplace=False,drop=True)\n",
        "y_hat = mainModel.predict(newx_test)\n",
        "y_pred = np.argmax(y_hat,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkzEIWF9grvK",
        "outputId": "09c90c09-cdff-4bf2-a387-468567466fbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 4, 2, ..., 7, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "metricsytest = unhotytest.to_numpy()\n",
        "metricsytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocxl_N55Rjvk",
        "outputId": "00aa7b6c-3de4-4137-a227-213d676d66a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       755\n",
            "           1       1.00      1.00      1.00      1384\n",
            "           2       0.69      0.73      0.71       779\n",
            "           3       0.58      0.56      0.57       494\n",
            "           4       0.61      0.70      0.65      1258\n",
            "           5       0.42      0.60      0.49       275\n",
            "           6       0.86      0.60      0.71       322\n",
            "           7       0.64      0.51      0.57      1120\n",
            "\n",
            "    accuracy                           0.74      6387\n",
            "   macro avg       0.71      0.70      0.70      6387\n",
            "weighted avg       0.75      0.74      0.74      6387\n",
            "\n",
            "{2: 'MESSAGING DOMINO', 4: 'SERVER MANAGEMENT', 7: 'submodel', 5: 'STORAGE SUPPORT', 6: 'Server Management - AIX', 1: 'I-Prompt', 3: 'SECURITY MANAGEMENT', 0: 'DB MANAGEMENT - ORACLE'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(metricsytest, y_pred))\n",
        "print(deDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpm7qTz4h1f0",
        "outputId": "77cd00a6-cb23-44fa-ffea-feecbc4066a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 2s 66ms/step\n"
          ]
        }
      ],
      "source": [
        "mininewy_test = miniy_test.reset_index(inplace=False,drop=True)\n",
        "mininewx_test = minix_test.reset_index(inplace=False,drop=True)\n",
        "miniy_hat = miniModel.predict(mininewx_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl4eeWFdz90L",
        "outputId": "d568bb4e-42e2-4ea9-eb4a-6b9887dbf3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116/116 [==============================] - 7s 63ms/step\n"
          ]
        }
      ],
      "source": [
        "ipromptHat = mainModel.predict(ipromptDf[\"Description\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uepQDd16h636",
        "outputId": "731c0aef-b692-4d0b-d16f-84f1420a4f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 5, ..., 5, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "miniy_pred = np.argmax(miniy_hat,axis=1)\n",
        "miniy_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhjWW1YOh7Vh",
        "outputId": "2efe200e-7fd2-4efe-d5e6-b3d59abdb7b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 4, ..., 5, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "minimetricsytest = miniunhotytest.to_numpy()\n",
        "minimetricsytest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAIW7D3Ah_ay",
        "outputId": "333dfa7f-e36f-4c33-f5c6-c8e07025fbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78       202\n",
            "           1       0.92      0.87      0.89       235\n",
            "           2       1.00      0.88      0.94        78\n",
            "           3       0.78      0.77      0.78       140\n",
            "           4       0.49      0.59      0.53        46\n",
            "           5       0.69      0.82      0.75       244\n",
            "           6       0.69      0.51      0.59        57\n",
            "           7       0.70      0.46      0.55       118\n",
            "\n",
            "    accuracy                           0.77      1120\n",
            "   macro avg       0.75      0.72      0.73      1120\n",
            "weighted avg       0.77      0.77      0.76      1120\n",
            "\n",
            "{5: 'Server Management - Linux', 1: 'DB MANAGEMENT - SQL', 3: 'NETWORK MANAGEMENT', 0: 'BACKUP MANAGEMENT', 2: 'Infosec', 6: 'Server Management - SOLARIS', 7: 'Server Management-AVPM', 4: 'SERVER MANAGEMENT - UNIX'}\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(minimetricsytest, miniy_pred))\n",
        "print(miniDict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foa5TPeQ0OaM",
        "outputId": "5cba6101-aaed-4771-96d2-46598277fee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      3692\n",
            "\n",
            "    accuracy                           1.00      3692\n",
            "   macro avg       1.00      1.00      1.00      3692\n",
            "weighted avg       1.00      1.00      1.00      3692\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ipromptPred = np.argmax(ipromptHat,axis=1)\n",
        "print(classification_report(ipromptDf[\"Group\"], ipromptPred))\n",
        "# Should be 100%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}