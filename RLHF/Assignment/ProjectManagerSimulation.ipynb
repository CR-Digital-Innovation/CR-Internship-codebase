{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CqU22WlKEleR",
        "outputId": "542f8b89-597a-4175-d7ea-918943bae12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.25\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.75\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.75\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | P | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | P | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.75\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 6\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 7\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 10\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 10\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 10\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 12\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 12\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 12\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 12\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 13\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 16\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 17\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.25\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.75\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 19\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | P | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.75\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 20\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 20\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 20\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 21\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 21\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.35\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | P | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Pending Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | P | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | P | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | P | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | P | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | P | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | P | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | P | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | P | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | P | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | P | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | P | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | P | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | P | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 22\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 23\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 23\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Adjust Strategy\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 23\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Define New Strategy\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | P | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Ongoing Task\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | P | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Resource Shortage\n",
            "Agent's Action Outcome:\n",
            "Reward: 1.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | P | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Task Completed\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.5\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 24\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Review Progress\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 25\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Reallocate Resources\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 26\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | P | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Unknown Problem\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "Correct Actions Count: 26\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Communicate Changes\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | 5 | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | P | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Communicate\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| 0 | P | 5 | 8 | 1 | 6 | 8 | 8 |\n",
            "| 1 | 4 | 4 | 6 | 7 | 3 | 8 | 1 |\n",
            "| 2 | 8 | 6 | 3 | 8 | 5 | 2 | 0 |\n",
            "| 3 | 8 | 8 | 4 | 6 | 8 | 0 | 1 |\n",
            "| 4 | 2 | 3 | 0 | 7 | 3 | 4 | 1 |\n",
            "| 5 | 0 | 6 | 1 | 8 | 2 | 0 | 6 |\n",
            "| 6 | 3 | 2 | 0 | 2 | 2 | 0 | 6 |\n",
            "+---+---+---+---+---+---+---+---+\n",
            "Agent's Chosen Action: Initiate Task\n",
            "Current State: Empty\n",
            "Agent's Action Outcome:\n",
            "Reward: 0.0\n",
            "Please rate the agent's action (1 to 5, where 5 is excellent): 5\n",
            "Agent has taken the correct actions for each state. Agent wins!\n",
            "Episode 1 - Total Reward: 24.1\n",
            "Correct Actions Count: 32\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-529ae12d9222>\u001b[0m in \u001b[0;36m<cell line: 319>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Calculate the next state based on the selected action (same as during training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-529ae12d9222>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Explore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exploit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3043\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m     \"\"\"\n\u001b[0;32m-> 3045\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3046\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "correct_actions_sequence = {\n",
        "    0: 0,  # Empty - Initiate Task\n",
        "    1: 1,  # Resource Shortage - Resource Reallocation\n",
        "    2: 4,  # Ongoing Task - Progress Review\n",
        "    3: 5,  # Pending Task - Adjust Strategy\n",
        "    4: 2,  # Progress Review - Review Progress\n",
        "    5: 3,  # Strategy Adjustment - Define New Strategy\n",
        "    6: 6,  # Define Strategy - Define Strategy\n",
        "    7: 5,  # Communicate - Communicate Changes\n",
        "    8: 0,  # Task Completed - Initiate Task\n",
        "}\n",
        "\n",
        "def custom_reward(current_state, next_state):\n",
        "    state_desirability = {\n",
        "        0: 1,  # Empty\n",
        "        1: 0.5,  # Resource Shortage\n",
        "        2: 1.5,  # Ongoing Task\n",
        "        3: 0.8,  # Pending Task\n",
        "        4: 1.2,  # Progress Review\n",
        "        5: 1.5,  # Strategy Adjustment\n",
        "        6: 1.8,  # Define Strategy\n",
        "        7: 1,  # Communicate\n",
        "        8: 2,  # Task Completed\n",
        "    }\n",
        "\n",
        "    unknown_problem_penalty = -0.5  # Adjust this penalty value as needed\n",
        "\n",
        "    # Check if the next_state is a valid key in the dictionary\n",
        "    if current_state in state_desirability and next_state in state_desirability:\n",
        "        current_desirability = state_desirability[current_state]\n",
        "        next_desirability = state_desirability[next_state]\n",
        "        desirability_change = next_desirability - current_desirability\n",
        "\n",
        "        if next_state == 9:  # Check if the next state is an \"Unknown Problem\" state\n",
        "            desirability_change += unknown_problem_penalty\n",
        "\n",
        "        if desirability_change > 0:\n",
        "            reward_weight = 1.0\n",
        "        elif desirability_change < 0:\n",
        "            reward_weight = -0.5\n",
        "        else:\n",
        "            reward_weight = 0.1\n",
        "\n",
        "        reward = desirability_change * reward_weight\n",
        "    else:\n",
        "        reward = 0.0  # Default reward if states are not in the dictionary\n",
        "\n",
        "    return reward\n",
        "\n",
        "class ProjectManagementEnv:\n",
        "\n",
        "    def __init__(self, grid_size=5, initial_state=0, end_cell=(6, 6)):\n",
        "        self.grid_size = grid_size\n",
        "        self.num_states = self.grid_size ** 2\n",
        "        self.num_actions = 6\n",
        "        self.max_episodes = 100\n",
        "\n",
        "        self.grid = np.arange(self.num_states).reshape(self.grid_size, self.grid_size)\n",
        "        self.agent_position = (0, 0)\n",
        "        self.episode = 0\n",
        "        self.state = initial_state\n",
        "\n",
        "        self.state_names = {\n",
        "            0: \"Empty\",\n",
        "            1: \"Resource Shortage\",\n",
        "            2: \"Ongoing Task\",\n",
        "            3: \"Pending Task\",\n",
        "            4: \"Progress Review\",\n",
        "            5: \"Strategy Adjustment\",\n",
        "            6: \"Define Strategy\",\n",
        "            7: \"Communicate\",\n",
        "            8: \"Task Completed\"\n",
        "        }\n",
        "        self.agent_position = (initial_state // self.grid_size, initial_state % self.grid_size)\n",
        "        self.end_cell = end_cell\n",
        "\n",
        "        self.place_states_randomly()  # Place states randomly after defining state_names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def place_states_randomly(self):\n",
        "        unique_states = list(self.state_names.keys())\n",
        "        self.grid = np.random.choice(unique_states, self.grid_size * self.grid_size, replace=True).reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = 0\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action,movement):\n",
        "\n",
        "        if movement == 'u':\n",
        "            next_row = max(0, self.agent_position[0] - 1)\n",
        "            next_state = next_row * self.grid_size + self.agent_position[1]\n",
        "        elif movement == 'd':\n",
        "            next_row = min(self.grid_size - 1, self.agent_position[0] + 1)\n",
        "            next_state = next_row * self.grid_size + self.agent_position[1]\n",
        "        elif movement == 'l':\n",
        "            next_col = max(0, self.agent_position[1] - 1)\n",
        "            next_state = self.agent_position[0] * self.grid_size + next_col\n",
        "        elif movement == 'r':\n",
        "            next_col = min(self.grid_size - 1, self.agent_position[1] + 1)\n",
        "            next_state = self.agent_position[0] * self.grid_size + next_col\n",
        "        else:\n",
        "            next_state = self.state  # Stay in the same state\n",
        "\n",
        "        self.agent_position = (next_state // self.grid_size, next_state % self.grid_size)\n",
        "        self.grid[self.agent_position[0], self.agent_position[1]] = self.state\n",
        "\n",
        "        next_state = self.agent_position[0] * self.grid_size + self.agent_position[1]\n",
        "\n",
        "        reward = custom_reward(self.state, next_state)\n",
        "\n",
        "\n",
        "        done = False\n",
        "        if self.agent_position == self.end_cell:\n",
        "            done = True\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "\n",
        "    def set_max_episodes(self, max_episodes):\n",
        "        self.max_episodes = max_episodes\n",
        "\n",
        "    def render(self, action):\n",
        "        action_labels = {\n",
        "            0: \"Initiate Task\",\n",
        "            1: \"Reallocate Resources\",\n",
        "            2: \"Review Progress\",\n",
        "            3: \"Adjust Strategy\",\n",
        "            4: \"Define New Strategy\",\n",
        "            5: \"Communicate Changes\"\n",
        "        }\n",
        "\n",
        "        table = PrettyTable()\n",
        "        table.field_names = [\"\"] + [str(col) for col in range(self.grid_size)]\n",
        "\n",
        "        for row in range(self.grid_size):\n",
        "            row_data = [str(row)]\n",
        "            for col in range(self.grid_size):\n",
        "                state = self.grid[row, col] % 10\n",
        "                if (row, col) == self.agent_position:\n",
        "                    row_data.append(\"P\")\n",
        "                elif state in self.state_names:\n",
        "                    row_data.append(str(state))\n",
        "                else:\n",
        "                    row_data.append(\"X\")  # Display \"X\" for obstacles (Unknown Problem states)\n",
        "            table.add_row(row_data)\n",
        "\n",
        "        print(table)\n",
        "        print(f\"Agent's Chosen Action: {action_labels[action]}\")\n",
        "\n",
        "        if self.state in self.state_names:\n",
        "            current_state_name = self.state_names[self.state]\n",
        "            print(f\"Current State: {current_state_name}\")\n",
        "        else:\n",
        "            print(\"Current State: Unknown Problem\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "\n",
        "    def __init__(self, num_states, num_actions, initial_learning_rate=0.1, discount_factor=0.9, exploration_prob=0.5,\n",
        "                 learning_rate_decay_rate=0.95, min_learning_rate=0.01):\n",
        "        self.num_states = num_states\n",
        "        self.num_actions = num_actions\n",
        "        self.learning_rate = initial_learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_prob = exploration_prob\n",
        "        self.learning_rate_decay_rate = learning_rate_decay_rate\n",
        "        self.min_learning_rate = min_learning_rate\n",
        "\n",
        "        self.q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.exploration_prob:\n",
        "            return np.random.choice(self.num_actions)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state, :])  # Exploit\n",
        "\n",
        "    def update_q_value(self, state, action, reward, next_state, next_state_valid):\n",
        "        if next_state_valid:  # Check if the next state is not an \"Unknown Problem\" state\n",
        "            max_next_action_value = np.max(self.q_table[next_state, :])\n",
        "            self.q_table[state, action] += self.learning_rate * (\n",
        "                reward + self.discount_factor * max_next_action_value - self.q_table[state, action]\n",
        "            )\n",
        "        else:\n",
        "            self.q_table[state, action] = float('-inf')  # Set Q-value to negative infinity for \"Unknown Problem\" states\n",
        "\n",
        "        self.decay_learning_rate()  # Decay learning rate here\n",
        "\n",
        "        # Check if the user rating is 5 or close to it\n",
        "        if user_rating >= 4:\n",
        "         state = next_state  # No need to change state if the action is rated 5\n",
        "        else:\n",
        "         state = next_state\n",
        "    def decay_learning_rate(self):\n",
        "        self.learning_rate = max(self.learning_rate * self.learning_rate_decay_rate, self.min_learning_rate)\n",
        "\n",
        "    def get_user_feedback(self, reward):\n",
        "        print(\"Agent's Action Outcome:\")\n",
        "        print(f\"Reward: {reward}\")\n",
        "        rating = input(\"Please rate the agent's action (1 to 5, where 5 is excellent): \")\n",
        "        return int(rating)\n",
        "\n",
        "end_cell_position = (6, 6)\n",
        "env = ProjectManagementEnv(grid_size=7, end_cell=end_cell_position)\n",
        "env.set_max_episodes(1)\n",
        "agent = QLearningAgent(num_states=env.num_states, num_actions=env.num_actions,\n",
        "                           initial_learning_rate=0.1, discount_factor=0.95, exploration_prob=0.7)\n",
        "agent.env = env\n",
        "\n",
        "action_labels = [\n",
        "    \"Initiate Task\", \"Reallocate Resources\", \"Review Progress\",\n",
        "    \"Adjust Strategy\", \"Define New Strategy\", \"Communicate Changes\"\n",
        "]\n",
        "\n",
        "for episode in range(env.max_episodes):\n",
        "    env.episode = episode\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    correct_actions_count = 0  # Count of correct actions taken by the agent\n",
        "    consecutive_correct_actions = 0  # Count of consecutive correct actions\n",
        "\n",
        "    while not done:\n",
        "        action = agent.select_action(state)\n",
        "        env.render(action)\n",
        "\n",
        "        # Calculate the next state based on the selected action\n",
        "        if action == 0:  # Up\n",
        "            next_row = max(0, env.agent_position[0] - 1)\n",
        "            next_state = next_row * env.grid_size + env.agent_position[1]\n",
        "        elif action == 1:  # Down\n",
        "            next_row = min(env.grid_size - 1, env.agent_position[0] + 1)\n",
        "            next_state = next_row * env.grid_size + env.agent_position[1]\n",
        "        elif action == 2:  # Left\n",
        "            next_col = max(0, env.agent_position[1] - 1)\n",
        "            next_state = env.agent_position[0] * env.grid_size + next_col\n",
        "        elif action == 3:  # Right\n",
        "            next_col = min(env.grid_size - 1, env.agent_position[1] + 1)\n",
        "            next_state = env.agent_position[0] * env.grid_size + next_col\n",
        "        else:\n",
        "            next_state = state  # Stay in the same state\n",
        "\n",
        "        # Determine if the next state is valid (not an \"Unknown Problem\" state)\n",
        "        next_state_valid = next_state not in env.state_names or env.state_names[next_state] != \"Unknown Problem\"\n",
        "\n",
        "        reward = custom_reward(state, next_state)\n",
        "\n",
        "\n",
        "        # Get user feedback for the agent's action\n",
        "        user_rating = agent.get_user_feedback(reward)\n",
        "\n",
        "        # Update Q-values based on the Q-learning update equation\n",
        "        agent.update_q_value(state, action, user_rating, next_state, next_state_valid)  # Pass next_state_valid here\n",
        "\n",
        "        agent.decay_learning_rate()\n",
        "\n",
        "        if user_rating >= 4:\n",
        "         state = next_state\n",
        "         consecutive_correct_actions += 1\n",
        "        else:\n",
        "         state = next_state  # Move to another state in the grid\n",
        "         consecutive_correct_actions = 0\n",
        "\n",
        "        # Check if the action taken by the agent is correct\n",
        "        if state in correct_actions_sequence and action == correct_actions_sequence[state]:\n",
        "            correct_actions_count += 1\n",
        "            consecutive_correct_actions += 1\n",
        "        else:\n",
        "            consecutive_correct_actions = 0\n",
        "\n",
        "            print(f\"Correct Actions Count: {correct_actions_count}\")\n",
        "\n",
        "\n",
        "        # Update current state and agent's position in the grid\n",
        "        env.state = next_state\n",
        "        env.agent_position = (next_state // env.grid_size, next_state % env.grid_size)\n",
        "\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "        if env.agent_position == env.end_cell:\n",
        "            done = True\n",
        "            print(\"Agent has reached the end cell. Episode completed.\")\n",
        "\n",
        "        # Clear the terminal for a cleaner display\n",
        "        import os\n",
        "        os.system('clear')\n",
        "\n",
        "        # Check if the agent has taken the correct actions for each state in the correct sequence\n",
        "        if consecutive_correct_actions >= len(correct_actions_sequence):\n",
        "            print(\"Agent has taken the correct actions for each state. Agent wins!\")\n",
        "            break\n",
        "\n",
        "    print(f\"Episode {episode + 1} - Total Reward: {total_reward}\")\n",
        "    print(f\"Correct Actions Count: {correct_actions_count}\")\n",
        "    print(\"-\" * 40)  # Print a separator line between episodes\n",
        "\n",
        "\n",
        "# Evaluation parameters\n",
        "num_evaluation_episodes = 10\n",
        "\n",
        "# Initialize evaluation environment\n",
        "evaluation_env = ProjectManagementEnv(grid_size=7, end_cell=end_cell_position)\n",
        "evaluation_env.set_max_episodes(num_evaluation_episodes)\n",
        "\n",
        "# List to store evaluation results\n",
        "evaluation_results = []\n",
        "\n",
        "# Run evaluation episodes\n",
        "for episode in range(num_evaluation_episodes):\n",
        "    state = evaluation_env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    correct_actions_count = 0\n",
        "\n",
        "    while not done:\n",
        "        action = agent.select_action(state)\n",
        "\n",
        "        # Calculate the next state based on the selected action (same as during training)\n",
        "        next_state, reward, done = evaluation_env.step(action, movement=None)\n",
        "\n",
        "        # Check if the action taken by the agent is correct (same as during training)\n",
        "        if state in correct_actions_sequence and action == correct_actions_sequence[state]:\n",
        "            correct_actions_count += 1\n",
        "\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    # Store evaluation results for this episode\n",
        "    evaluation_results.append({\n",
        "        \"Episode\": episode + 1,\n",
        "        \"Total Reward\": total_reward,\n",
        "        \"Correct Actions Count\": correct_actions_count\n",
        "    })\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"\\nEvaluation Results:\")\n",
        "for result in evaluation_results:\n",
        "    print(result)\n",
        "\n",
        "# Calculate average performance metrics\n",
        "average_total_reward = np.mean([result[\"Total Reward\"] for result in evaluation_results])\n",
        "average_correct_actions = np.mean([result[\"Correct Actions Count\"] for result in evaluation_results])\n",
        "\n",
        "print(\"\\nAverage Performance Metrics:\")\n",
        "print(f\"Average Total Reward: {average_total_reward}\")\n",
        "print(f\"Average Correct Actions Count: {average_correct_actions}\")"
      ]
    }
  ]
}